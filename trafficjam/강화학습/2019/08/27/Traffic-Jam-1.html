<!DOCTYPE html>
<html>

  <head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134826755-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134826755-1');
  </script>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>(TrafficJAM) 교통제어 강화학습 논문 정리 - Diagnoising Reinforcement Learning for Traffic Signal Control by Guanjie Zheng (2019)</title>
  <meta name="description" content="요약 목적">
  
  <meta name="author" content="Jinhyeok Jeong">
  <meta name="copyright" content="&copy; Jinhyeok Jeong 2022">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/monokai-sublime.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="manifest" href="/assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  
  <!-- Facebook OGP cards -->
  <meta property="og:description" content="요약 목적" />
  <meta property="og:url" content="https://zoomkoding.github.io" />
  <meta property="og:site_name" content="줌코딩의 코딩일기" />
  <meta property="og:title" content="(TrafficJAM) 교통제어 강화학습 논문 정리 - Diagnoising Reinforcement Learning for Traffic Signal Control by Guanjie Zheng (2019)" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="https://zoomkoding.github.io/assets/instacode.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="612" />
  <meta property="og:image:height" content="605" />
  

  
  <!-- Twitter: card tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="(TrafficJAM) 교통제어 강화학습 논문 정리 - Diagnoising Reinforcement Learning for Traffic Signal Control by Guanjie Zheng (2019)">
  <meta name="twitter:description" content="요약 목적">
  <meta name="twitter:image" content="https://zoomkoding.github.io/assets/instacode.png">
  <meta name="twitter:url" content="https://zoomkoding.github.io">
  

  

  <!-- Site styles -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://zoomkoding.github.io/trafficjam/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/2019/08/27/Traffic-Jam-1.html">
  <link rel="alternate" type="application/rss+xml" title="줌코딩의 코딩일기" href="https://zoomkoding.github.io/feed.xml" />
</head>


  <body>

    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <a href="/" class="logo">
      
      <img src="/assets/Crewcials.jpeg" alt="줌코딩의 코딩일기">
      
    </a>
    <div class="nav-link new-blog outer">
      <button type="button" onclick="location.href='https://www.zoomkoding.com'">
        <div class="button-text">
          <img class="thumbnail" src="https://github.com/zoomKoding/zoomKoding.github.io/blob/source/zoomkoding-small.png?raw=true" alt="개발 블로그 테마 개발">
          <div class="label">
            <div class="name">zoomkoding.com</div>
            <div class="description">이전한 블로그로 이동하기</div>     
          </div>    
        </div>
         
      </button>
    </div>
  
    <nav role="navigation">
      <ul id="js-navigation-menu" class="navigation-menu show">
        
          
          <li class="nav-link"><a href="/about/">About</a>
          
        
          
        
          
        
          
        
          
          <li class="nav-link"><a href="/posts/">Posts</a>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        

        <li class="nav-link new-blog inner">
          <button type="button" onclick="location.href='https://www.zoomkoding.com'">
            <div class="button-text">
              <img class="thumbnail" src="https://github.com/zoomKoding/zoomKoding.github.io/blob/source/zoomkoding-small.png?raw=true" alt="개발 블로그 테마 개발">
              <div class="label">
                <div class="name">zoomkoding.com</div>
                <div class="description">이전한 블로그로 이동하기</div>     
              </div>    
            </div>
             
          </button>
        </li>
      </ul>
    </nav>
  </div>
</header>


    <div class="page-content">
        <div class="post">

<div class="post-header-container has-cover" style="background-image: url(/assets/instacode.png);">
  <div class="scrim has-cover">
    <header class="post-header">
      <h1 class="title">(TrafficJAM) 교통제어 강화학습 논문 정리 - Diagnoising Reinforcement Learning for Traffic Signal Control by Guanjie Zheng (2019)</h1>
      <p class="info">by <strong>줌코딩</strong></p>
    </header>
  </div>
</div>

<div class="wrapper">



<section class="post-meta">
  <div class="post-date">August 27, 2019</div>
  <div class="post-categories">
  in 
    
    <a href="/category/trafficJAM">Trafficjam</a>, 
    
  
    
    <a href="/category/강화학습">강화학습</a>
    
  
  </div>
</section>
<div class="coupang-partners">
  <div class="items">
    <iframe src="https://coupa.ng/cbvuWm" width="120" height="240" frameborder="0" scrolling="no" referrerpolicy="unsafe-url"></iframe>
    <iframe src="https://coupa.ng/cbvuuT" width="120" height="240" frameborder="0" scrolling="no" referrerpolicy="unsafe-url"></iframe>
    <iframe src="https://coupa.ng/cbvuYz" width="120" height="240" frameborder="0" scrolling="no" referrerpolicy="unsafe-url"></iframe>
    <iframe src="https://coupa.ng/cbvuZQ" width="120" height="240" frameborder="0" scrolling="no" referrerpolicy="unsafe-url"></iframe>
    <iframe src="https://coupa.ng/cbvu3h" width="120" height="240" frameborder="0" scrolling="no" referrerpolicy="unsafe-url"></iframe>
  </div>
</div>
<article class="post-content">
  <h2 id="요약-목적">요약 목적</h2>

<blockquote>
  <ul>
    <li>이 자료는 개인 프로젝트를 진행하기 위함이라 강화학습 쪽으로 많이 편중될 수 있음을 참고하길 바란다.</li>
  </ul>
</blockquote>

<h2 id="abstract">Abstract</h2>

<blockquote>
  <ul>
    <li>이 논문은 reinforcement learning(RL)을 traffic signal control에 적용시키는데 있어서 가자 중요한 부분인 <strong>reward와 state 설정을 어떻게 할 것인가</strong>에 대한 solution과 이를 기반으로 <strong>classic transportation theory에 RL을 적용시키는 방안(LIT)을 제안</strong>하고 있다.</li>
  </ul>
</blockquote>

<h2 id="introduction">Introduction</h2>

<h3 id="setting-the-reward">Setting the Reward</h3>

<blockquote>
  <ul>
    <li>교통신호 시스템 제어의 궁극적인 목표는 <strong>신호를 최적화</strong>하는 것이 아니라 <strong>각 차량의 주행시간을 최소화</strong> 하는 것이다.</li>
    <li>주행시간에 영향을 미치는 것은 신호 뿐 아니라 여러 요인들이 존재한다.</li>
    <li>이를 위해 기존 연구들은 queue length, waiting time, number of switches in traffic signal, total delay 등을 복합적으로 이용해서 reward를 표현하였다.</li>
    <li>여기서 문제는 이렇게 최적화한 reward가 주행시간을 최적화하는지에 대한 확신이 없다.</li>
    <li>아래 figure 1은 reward 설정에 따른 주행시간의 추이를 실험한 결과이다.</li>
    <li>이는 reward에 <strong>특징을 추가하는 것이 주행시간을 최적화하지 않음</strong>을 보여준다.</li>
  </ul>
</blockquote>

<p><img src="/assets/TJ1-1.png" alt="사진" /></p>

<blockquote>
  <ul>
    <li>실험에서 보이듯이 reward를 queue length로 설정하는 것이 제일 좋은 주행시간을 낸다.</li>
    <li>이 논문에서는 <strong>queue length의 최적화가 주행시간의 최적화</strong>라는 것은 앞으로 증명될 예정이다.</li>
  </ul>
</blockquote>

<h3 id="setting-the-state">Setting the State</h3>

<blockquote>
  <ul>
    <li>요즘 교통 제어 RL의 추세는 state에 더 많은 feature을 추가해서 학습하는 것이다.</li>
    <li>때론 이미지를 state에 추가해서 학습하기도 한다.</li>
    <li>하지만 <strong>이는 오히려 agent가 학습하는데 시간을 늘리게 되고, 학습시간이 늘어나는 것이 significant performance gain을 가져다 주지는 않는다.</strong></li>
    <li>이 논문에서는 교통 제어 RL의 <strong>state는 차량수(number of vehicles)와 현재 교통 신호(current traffic signal phase)</strong>면 충분하다는 것을 보일 것이다.</li>
  </ul>
</blockquote>

<h2 id="problem-definition">Problem definition</h2>

<h3 id="preliminary">Preliminary</h3>

<blockquote>
  <ul>
    <li>Entering Direction : 4방향(E, W, N, S)</li>
    <li>Signal Phase : 두개만 초록불로 표현 할 것이다. ex) WT-ET : 서쪽 초록, 동쪽 초록, 나머지 빨간</li>
  </ul>
</blockquote>

<h3 id="rl-environment">RL Environment</h3>

<blockquote>
  <ul>
    <li>RL Environment란 현재 교차로의 상태를 보여준다.</li>
    <li>Agent는 현재 환경을 관찰하고 이를 state($s_t$)로 표현한다.</li>
    <li>그리고 미리 만들어 놓은 signal phase order를 agent에게 제공한다.</li>
    <li>agent는 timestamp 마다 신호를 바꿀지 말지를 결정하고 action($a_t$)을 취한다.</li>
    <li>여기서 action을 취하고 나면 state는 $s_{t+1}$로 변하게 되고 이에 따른 reward($r$)이 주어지게 된다.</li>
    <li>reward는 $R(s_t,a_t)$로 state에서 action을 취했을 때 주어지는 보상을 의미한다.</li>
    <li>Problem Definition은 한다.</li>
  </ul>
</blockquote>

<p><strong><em>Problem 1. state의 set인 S와 action의 set인 A, Reward function이 주어졌을 때 각 state에 최대의 discounted reward 반환하는 최적의 action을 찾는 policy를 찾아라!</em></strong></p>

<blockquote>
  <ul>
    <li>반환값을 위한 공식은 다음과 같다.(미래의 값에는 적당한 $\Gamma$를 곱해준다.)</li>
  </ul>
</blockquote>

<p><img src="/assets/TJ1-2.png" alt="사진" /></p>

<h3 id="state-action-reward-definition">State, Action, Reward Definition</h3>

<blockquote>
  <ul>
    <li>state : number of vehicles on each lane j($v_{j,t}$), the current signal phase $p_t$</li>
    <li>action : 신호가 바뀌는 거면 $a_t = 1$, 아니면 $a_t = 0$</li>
    <li>rewards : 모든 lane의 queue 길이의 합(합이 작은 경우가 좋은 것이기 때문에 음수를 취한다.)</li>
  </ul>
</blockquote>

\[R_t = -\sum_{j=1}^M q_{t,j}\]

<h3 id="objective">Objective</h3>

<blockquote>
  <ul>
    <li>이 논문의 목표는 위의 문제를 해결하는 RL 알고리즘을 찾고</li>
    <li>이를 classic transportation theory랑 연결시켜서 state와 reward 정의가 잘됐다는 걸 증명하고</li>
    <li>실제로 다른 논문들보다 잘하는지 증명하는 것이다.</li>
  </ul>
</blockquote>

<h2 id="method">Method</h2>

<blockquote>
  <ul>
    <li>RL에 대해 잘 모르고 막 적용을 하는 사람이 늘다보니까 state와 reward가 redundant한 경우가 상당히 많고 불필요한 것들이 마구 들어가 있다..(자신감 뿜뿜)</li>
    <li>이 논문은 필요한 애들만 있는 simple한 RL 모델을 소개한다.</li>
  </ul>
</blockquote>

<h3 id="sketch-of-our-rl-method">Sketch of Our RL Method</h3>

<blockquote>
  <ul>
    <li>우리 알고리즘은 앞서 설명한 reward와 state를 이용할 것이다.</li>
    <li>강화학습 알고리즘으로는 DQN 알고리즘을 사용할 예정이다.</li>
    <li>state는 아래 그림과 같이 차량 수에 대한 정보와 현재 신호에 대한 정보가 더해져서 구성될 것이다.</li>
    <li>reward는 action을 취한 후에 주어지는 모든 -(queue의 길이의 합)으로 표현할 수 있다.</li>
  </ul>
</blockquote>

<p><img src="/assets/TJ1-3.png" alt="사진" /></p>

<h3 id="connecting-rl-with-transportation-theory">Connecting RL with Transportation Theory</h3>

<blockquote>
  <ul>
    <li>reward는 queue length로, state는 레인별 차량 수와 현재 신호로 여길 것이다.</li>
  </ul>
</blockquote>

<h4 id="reward-proof">Reward Proof</h4>

<blockquote>
  <ul>
    <li>0부터 일정시간 동안 M개 레인의 큐의 개수를 모두 더한 값이 가장 작게 하는 policy를 우리의 목표이다.</li>
    <li>즉 아래 공식과 같이 표현할 수 있고, 이는 $\tau$까지의 시간동안 각 <strong>큐가 가지는 시간당 평균 길이</strong>이다.</li>
  </ul>
</blockquote>

<p><img src="/assets/TJ1-4.png" alt="사진" /></p>

<blockquote>
  <ul>
    <li>그리고 각 시간 대 별로 대기하고 있는 차량의 수를 $e_t$라고 했을 때 이는 각 시간 대에 큐에 있는 차량의 수로 표현 할 수 있다.</li>
  </ul>
</blockquote>

\[e_t = sum_{j=1}^M q_{t,j}\]

<blockquote>
  <ul>
    <li>그렇다면 총 대기시간(W)는 $\tau$까지의 시간 동안의 모든 $e_t$의 합으로 표현할 수 있고 이는 결국 $\tau$(시간)* 총 q 길이의 평균으로 표현할 수 있다.</li>
  </ul>
</blockquote>

<p><img src="/assets/TJ1-5.png" alt="사진" /></p>

<blockquote>
  <ul>
    <li>이것을 각 차량이 교차로를 통과하는데 추가로 필요한 시간 Delay(D)는 다음과 같이 나타낼 수 있다.</li>
  </ul>
</blockquote>

\[D_i = sum_{t=1}^\tau q_{t,i}\]

<blockquote>
  <ul>
    <li>위의 식들을 기반으로 모든 차량의 평균 주행시간을 식으로 표현하면 다음과 같다.</li>
    <li>여기서 $l/\mu$는 총 이동거리/속도를 나타낸다.</li>
  </ul>
</blockquote>

<p><img src="/assets/TJ1-6.png" alt="사진" /></p>

<blockquote>
  <ul>
    <li>결국 평균 주행거리는 평균 queue의 길이와 비례함을 볼 수 있다.</li>
  </ul>
</blockquote>

<p><img src="/assets/TJ1-7.png" alt="사진" /></p>

<blockquote>
  <ul>
    <li>이는 queue의 길이를 감소시키면 주행거리가 감소될 것임을 증명한다.</li>
  </ul>
</blockquote>

<h3 id="state-proof">State Proof</h3>

<blockquote>
  <ul>
    <li>state를 설명하는데 있어도 각 레인의 차량수와 현재 신호 상태만 있다면 state를 충분히 표현할 수 있다.</li>
    <li>현재 시간에서의 신호($p_t$)를 $p^k$라고 하면 다음 시간에서의 각 레인의 차량수는 다음과 같이 표현 가능하다.</li>
  </ul>
</blockquote>

\[v_{t+1,j} = v_{t,j} + f_{in,j} - f_{out,j} * c_{t,j}\]

<blockquote>
  <ul>
    <li>여기서 t 시간에 j 레인이 빨간불이라면 $c_{t,j}$ 는 0이고 초록불이면 1이다.</li>
    <li>즉 원래 대기하고 있던 차량($v_{t,j}$)에 새로 들어온 차량($f_{in,j}$)에다가 신호가 바뀌었다면 나간 빠져나간 차량의 수($f_{out,j} * c_{t,j}$)를 빼준 것이 $t+1$의 챠량의 수이다.</li>
    <li>이 때, 다음 신호는 다음과 같이 표현 할 수 있다.</li>
    <li>신호가 바뀌었다면($a_t = 1$) 다음 신호 상태로 아니라면 현재와 동일한 $p^k$로 한다.</li>
  </ul>
</blockquote>

<p><img src="/assets/TJ1-8.png" alt="사진" /></p>

<blockquote>
  <ul>
    <li>이를 통해 빨간불일 때의 $f_in$은 $f_{in,j} = v_{t+1,j} - v_{t,j}$로 초록불일 때의 $f_out$은 $f_{out,j} = v_{t,j} - v_{t+1,j} + f_{in,j}$로 표현할 수 있다.</li>
    <li>때문에 이론적으로 환경의 현재 상태는 $v_j$와 $p$만으로 표현이 가능하다.</li>
  </ul>
</blockquote>

<h3 id="analysis-of-traits-of-rl-approach">Analysis of Traits of RL Approach</h3>

<blockquote>
  <ul>
    <li>RL을 이용해서 얻을 수 있는 장점 3가지를 설명하고 있다.</li>
    <li>Online learning : 실시간으로 배우고 업데이트 한다.</li>
    <li>Sampling guidance : 과거에 reward가 높았던 학습 경험을 기반으로 행동한다.</li>
    <li>Forecast : Q-function을 이용해서 미래의 reward를 예측할 수 있다.</li>
  </ul>
</blockquote>

<h2 id="experiments">Experiments</h2>

<h3 id="experiment-setting">Experiment Setting</h3>

<blockquote>
  <ul>
    <li>SUMO라는 교통 simulator를 사용하여 다른 모델과 비교를 진행하였다.</li>
  </ul>
</blockquote>

<p><a href="https://www.youtube.com/watch?v=9MyIABer_NY">SUMO 소개 영상</a></p>

<blockquote>
  <ul>
    <li>SUMO에서 state를 제공받으면 그에 따라 신호체계를 변경하였다.</li>
    <li>각 차량의 travel time을 기준으로 비교하였다.</li>
    <li>일단 중국의 두도시(City A, B)와 LA의 실제 교통환경을 배경으로 실험을 진행한 결과 LIT가 확연히 빠른 것을 볼 수 있다.</li>
  </ul>
</blockquote>

<p><img src="/assets/TJ1-9.png" alt="사진" /></p>

<blockquote>
  <ul>
    <li>Uniform Traffic에서도 확연히 나은 모습을 볼 수 있었으며,</li>
    <li>Multi intersection 환경에서도 월등한 성과가 있었다.</li>
  </ul>
</blockquote>

<h2 id="conclusion">Conclusion</h2>

<blockquote>
  <ul>
    <li>LIT is good!</li>
    <li>Simple is the Best!</li>
  </ul>
</blockquote>

<h2 id="reference">Reference</h2>

<p>Guanjie Zheng, Xinshi Zang, Nan Xu, and Hua Wei. 2019. Diagnosing Reinforcement Learning for Traffic Signal Control</p>

<h2 id="느낀점">느낀점</h2>

<blockquote>
  <ul>
    <li>일단 RL을 적용해보는 것은 처음이라 걱정했는데 일단 여기서 말하는 대로 state와 reward에 대한 정의는 간단하게 해도 된다고 하니 일단은 다행이다.</li>
    <li>intelliLight에서 발전된 논문으로 intelliLight에 대한 논문(Intelligent Traffic Signal Control: Using Reinforcement Learning with Partial Detection) 또한 읽어 볼 필요가 있을 것 같다.</li>
  </ul>
</blockquote>

</article>
<div class="coupang-partners">
  <div class="items">
    <iframe src="https://coupa.ng/cbvuWm" width="120" height="240" frameborder="0" scrolling="no" referrerpolicy="unsafe-url"></iframe>
    <iframe src="https://coupa.ng/cbvuuT" width="120" height="240" frameborder="0" scrolling="no" referrerpolicy="unsafe-url"></iframe>
    <iframe src="https://coupa.ng/cbvuYz" width="120" height="240" frameborder="0" scrolling="no" referrerpolicy="unsafe-url"></iframe>
    <iframe src="https://coupa.ng/cbvuZQ" width="120" height="240" frameborder="0" scrolling="no" referrerpolicy="unsafe-url"></iframe>
    <iframe src="https://coupa.ng/cbvu3h" width="120" height="240" frameborder="0" scrolling="no" referrerpolicy="unsafe-url"></iframe>
  </div>
  <div class="description">
    이 포스팅은 쿠팡 파트너스 활동의 일환으로, 이에 따른 일정액의 수수료를 제공받습니다.
  </div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>




<section class="tags">
  <strong>Tags:</strong> <a href="/tag/trafficJAM">trafficJAM</a>,&nbsp;<a href="/tag/강화학습">강화학습</a>
</section>



<section class="rss">
  <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
</section>

<section class="share">
  <span>Share: </span>
  
    
    
    
    
    
    
    
    
  
</section>

	<section class="post-navigation">
		<span class="prev-post">
			
				<a href="/%EB%B0%B1%EC%A4%80/2019/08/26/baekjoon-2231.html">
					<span class="fa-stack fa-lg">
						<i class="fa fa-square fa-stack-2x"></i>
						<i class="fa fa-angle-double-left fa-stack-1x fa-inverse"></i>
					</span>
					<span class="page-number">(백준 알고리즘 문제풀이) 2231번 트리의 독립집합</span>
				</a>
			
		</span>
		<span class="next-post">
			
				<a href="/trafficjam/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/2019/08/28/Traffic-Jam-2.html">
					<span class="page-number">(TrafficJAM) 교통제어 강화학습 논문 정리 - IntelliLight, A Reinforcement Learning Approach for Intelligent Traffic Light Control by Hua Wei(2018)</span>
					<span class="fa-stack fa-lg">
						<i class="fa fa-square fa-stack-2x"></i>
						<i class="fa fa-angle-double-right fa-stack-1x fa-inverse"></i>
					</span>
				</a>
			
		</span>
	</section>




<section class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = 'zoomKoding';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



</div>
</div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h3 class="footer-heading">줌코딩의 코딩일기</h3>

    <div class="site-navigation">

      <p><strong>Site Map</strong></p>
      <ul class="pages">
        
        
          <li class="nav-link"><a href="/about/">About</a>
        
        
        
        
        
        
        
        
        
          <li class="nav-link"><a href="/posts/">Posts</a>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
      </ul>
    </div>

    <div class="site-contact">

      <p><strong>Contact</strong></p>
      <ul class="social-media-list">
        <li>
          <a href="mailto:zoomkoding@gmail.com">
            <i class="fa fa-envelope-o"></i>
            <span class="username">zoomkoding@gmail.com</span>
          </a>
        </li>

        
          
          <li>
            <a href="https://github.com/zoomkoding" title="Fork me on GitHub">
              <i class="fa fa-github"></i>
              <span class="username">ZoomKoding</span>
            </a>
          </li>
          
        

      </ul>
    </div>

    <div class="site-signature">
      <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
      <p class="text">Zoom in Coding from the Basic.</p>
    </div>

  </div>

</footer>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-1.11.2.min.js"></script>
<style>
.videoWrapper {
	position: relative;
	padding-bottom: 56.333%;
	height: 0;
    background: black;
}
.videoWrapper iframe {
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	height: 100%;
    border: 0;
}    
</style>

<script>
function get_youtube_id(url) {
    var p = /^(?:https?:\/\/)?(?:www\.)?(?:youtu\.be\/|youtube\.com\/(?:embed\/|v\/|watch\?v=|watch\?.+&v=))((\w|-){11})(?:\S+)?$/;
    return (url.match(p)) ? RegExp.$1 : false;
}
function vimeo_embed(url,el) {
    var id = false;
    $.ajax({
      url: 'https://vimeo.com/api/oembed.json?url='+url,
      async: true,
      success: function(response) {
        if(response.video_id) {
          id = response.video_id;
          if(url.indexOf('autoplay=1') !== -1) var autoplay=1; else var autoplay=0;
          if(url.indexOf('loop=1') !== -1) var loop=1; else var loop=0;
          var theInnerHTML = '<div class="videoWrapper"><iframe src="https://player.vimeo.com/video/'+id+'/?byline=0&title=0&portrait=0';
          if(autoplay==1) theInnerHTML += '&autoplay=1';
          if(loop==1) theInnerHTML += '&loop=1';
          theInnerHTML += '" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div>'; 
          el.innerHTML = theInnerHTML;
        }
      }
    });
}
function video_embed() {
    var p = document.getElementsByTagName('p');
    for(var i = 0; i < p.length; i++) {
        //check if this is an external url (that starts with https:// or http://
        if (p[i].innerHTML.indexOf("http://") == 0 ||
            p[i].innerHTML.indexOf("https://") == 0) {
            var youtube_id = get_youtube_id(p[i].innerHTML);
            if(youtube_id) {
                if(p[i].innerHTML.indexOf('autoplay=1') !== -1) var autoplay=1; else var autoplay=0;
                if(p[i].innerHTML.indexOf('loop=1') !== -1) var loop=1; else var loop=0;
                var theInnerHTML = '<div class="videoWrapper"><iframe width="720" height="420" src="https://www.youtube.com/embed/' + youtube_id + '?rel=0&showinfo=0';
                if(autoplay==1) theInnerHTML += '&autoplay=1';
                if(loop==1) theInnerHTML += '&loop=1&playlist='+youtube_id+'&version=3';
                theInnerHTML += '" frameborder="0" allowfullscreen></iframe></div>';
                p[i].innerHTML = theInnerHTML;
            }
            if(p[i].innerHTML.indexOf('vimeo.com') !== -1) {
                //ask vimeo for the id and place the embed
                vimeo_embed(p[i].innerHTML,p[i]);
            }
        }
    }
}
video_embed();

function mp3_embed() {
    var p = document.getElementsByTagName('p');
    for(var i = 0; i < p.length; i++) {
        if(p[i].innerHTML.indexOf('.mp3') !== -1) {
            var str = p[i].innerHTML.split('?');
            if(str.length == 1) str[1] = '';
            var str1 = str[1];
            str1 = str1.replace('&','').replace('&','');
            str1 = str1.replace('autoplay=1','').replace('autoplay=0','');
            str1 = str1.replace('loop=1','').replace('loop=0','');
            str1 = str1.replace('controls=0','').replace('controls=1','');

            if (str[0].lastIndexOf('.mp3', str[0].length - 4) === str[0].length - 4 && str1.length == 0) {
                if(str[1].indexOf('autoplay=1') !== -1) var autoplay=1; else var autoplay=0;
                if(str[1].indexOf('loop=1') !== -1) var loop=1; else var loop=0;
                if(str[1].indexOf('controls=0') !== -1) var controls=0; else var controls=1;
                var newInnerHTML = '<audio';
                if(autoplay==1) newInnerHTML += ' autoplay';
                if(loop==1) newInnerHTML += ' loop';
                if(controls==1) newInnerHTML += ' controls';
                newInnerHTML += '><source src="'+str[0]+'" type="audio/mpeg">Your browser does not support the audio element.</audio>';
                p[i].innerHTML = newInnerHTML;
            }
        }
    }
}
mp3_embed();
</script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/js/lightbox.min.js"></script>

<script type="text/javascript">
$(document).ready(function() {
  // Default syntax highlighting
  hljs.initHighlightingOnLoad();

  // Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });
});

</script>




<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-83878761-1', 'auto');
  ga('send', 'pageview', {
    'page': '/trafficjam/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/2019/08/27/Traffic-Jam-1.html',
    'title': '(TrafficJAM) 교통제어 강화학습 논문 정리 - Diagnoising Reinforcement Learning for Traffic Signal Control by Guanjie Zheng (2019)'
  });
</script>



  </body>

</html>
